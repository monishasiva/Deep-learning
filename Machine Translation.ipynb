{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":12723108,"sourceType":"datasetVersion","datasetId":8041678},{"sourceId":14746652,"sourceType":"kernelVersion"}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Step 1: Define dictionary\ndictionary = {\n    'hello': 'bonjour',\n    'world': 'monde',\n    'my': 'mon',\n    'name': 'nom',\n    'is': 'est'\n}\n\n# Step 2: Define grammar rules (not used yet)\ngrammar_rules = {\n    'SVO': ['subject', 'verb', 'object']\n}\n\n# Step 3: Translation function\ndef translate(sentence):\n    words = sentence.lower().split()  # split into words\n    translated_words = [dictionary.get(word, word) for word in words]  # look up each word\n    return ' '.join(translated_words)\n\n# Example usage\nsentence = \"Hello world\"\nprint(translate(sentence))  # Expected: \"bonjour monde\"\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-09-18T04:32:22.862669Z","iopub.execute_input":"2025-09-18T04:32:22.862915Z","iopub.status.idle":"2025-09-18T04:32:22.874550Z","shell.execute_reply.started":"2025-09-18T04:32:22.862882Z","shell.execute_reply":"2025-09-18T04:32:22.873676Z"}},"outputs":[{"name":"stdout","text":"bonjour monde\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Attention, Concatenate\nfrom tensorflow.keras.models import Model\nfrom sklearn.model_selection import train_test_split","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T04:55:33.239207Z","iopub.execute_input":"2025-09-18T04:55:33.239796Z","iopub.status.idle":"2025-09-18T04:55:33.243949Z","shell.execute_reply.started":"2025-09-18T04:55:33.239773Z","shell.execute_reply":"2025-09-18T04:55:33.243089Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"# Load data\ndef load_sentences(file, add_tokens=False):\n    with open(file, 'r', encoding='utf-8') as f:\n        lines = [line.strip() for line in f]\n    if add_tokens:\n        lines = ['<start> '+l+' <end>' for l in lines]\n    return lines\n\nen_sent = load_sentences('/kaggle/input/english-to-french/small_vocab_en.csv')\nfr_sent = load_sentences('/kaggle/input/english-to-french/small_vocab_fr.csv', add_tokens = True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T04:56:22.911759Z","iopub.execute_input":"2025-09-18T04:56:22.912350Z","iopub.status.idle":"2025-09-18T04:56:23.054239Z","shell.execute_reply.started":"2025-09-18T04:56:22.912326Z","shell.execute_reply":"2025-09-18T04:56:23.053036Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"def tokenize(texts):\n    tok = Tokenizer(filters='', lower=False)\n    tok.fit_on_texts(texts)\n    seq = tok.texts_to_sequences(texts)\n    return tok, pad_sequences(seq, padding='post')\n\nen_tok, en_seq = tokenize(en_sent)\nfr_tok, fr_seq = tokenize(fr_sent)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T04:56:37.543825Z","iopub.execute_input":"2025-09-18T04:56:37.544398Z","iopub.status.idle":"2025-09-18T04:56:43.515235Z","shell.execute_reply.started":"2025-09-18T04:56:37.544374Z","shell.execute_reply":"2025-09-18T04:56:43.514645Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"# Decoder input/output\ndec_in = fr_seq[:, :-1]\ndec_out = fr_seq[:, 1:]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T04:56:54.903987Z","iopub.execute_input":"2025-09-18T04:56:54.904263Z","iopub.status.idle":"2025-09-18T04:56:54.908153Z","shell.execute_reply.started":"2025-09-18T04:56:54.904244Z","shell.execute_reply":"2025-09-18T04:56:54.907289Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"X_tr, X_val, y_tr_in, y_val_in, y_tr_out, y_val_out = train_test_split(\n    en_seq, dec_in, dec_out, test_size=0.2, random_state=42\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T04:57:05.489789Z","iopub.execute_input":"2025-09-18T04:57:05.490081Z","iopub.status.idle":"2025-09-18T04:57:05.537691Z","shell.execute_reply.started":"2025-09-18T04:57:05.490061Z","shell.execute_reply":"2025-09-18T04:57:05.536911Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"# Model\nembed_dim, latent_dim = 256, 512\nenc_in = Input(shape=(en_seq.shape[1],))\nenc_emb = Embedding(len(en_tok.word_index)+1, embed_dim)(enc_in)\nenc_out, state_h, state_c = LSTM(latent_dim, return_sequences=True, return_state=True)(enc_emb)\n\ndec_inp = Input(shape=(dec_in.shape[1],))\ndec_emb = Embedding(len(fr_tok.word_index)+1, embed_dim)(dec_inp)\ndec_out, _, _ = LSTM(latent_dim, return_sequences=True, return_state=True)(dec_emb, initial_state=[state_h, state_c])\n\nattn = Attention()([dec_out, enc_out])\ndec_concat = Concatenate()([dec_out, attn])\ndec_dense = Dense(len(fr_tok.word_index)+1, activation='softmax')\noutputs = dec_dense(dec_concat)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T04:57:21.570701Z","iopub.execute_input":"2025-09-18T04:57:21.571391Z","iopub.status.idle":"2025-09-18T04:57:21.902220Z","shell.execute_reply.started":"2025-09-18T04:57:21.571356Z","shell.execute_reply":"2025-09-18T04:57:21.901638Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"model = Model([enc_in, dec_inp], outputs)\nmodel.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n\n# Train (increase epochs for better results)\nmodel.fit([X_tr, y_tr_in], y_tr_out, validation_data=([X_val, y_val_in], y_val_out),\n          batch_size=32, epochs=15)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T04:57:38.465918Z","iopub.execute_input":"2025-09-18T04:57:38.466654Z","iopub.status.idle":"2025-09-18T05:10:30.875614Z","shell.execute_reply.started":"2025-09-18T04:57:38.466631Z","shell.execute_reply":"2025-09-18T05:10:30.875033Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/15\n\u001b[1m3447/3447\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 15ms/step - accuracy: 0.7973 - loss: 0.7533 - val_accuracy: 0.9827 - val_loss: 0.0486\nEpoch 2/15\n\u001b[1m3447/3447\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 15ms/step - accuracy: 0.9871 - loss: 0.0386 - val_accuracy: 0.9924 - val_loss: 0.0236\nEpoch 3/15\n\u001b[1m3447/3447\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 15ms/step - accuracy: 0.9936 - loss: 0.0198 - val_accuracy: 0.9948 - val_loss: 0.0161\nEpoch 4/15\n\u001b[1m3447/3447\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 15ms/step - accuracy: 0.9956 - loss: 0.0134 - val_accuracy: 0.9956 - val_loss: 0.0140\nEpoch 5/15\n\u001b[1m3447/3447\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 15ms/step - accuracy: 0.9967 - loss: 0.0101 - val_accuracy: 0.9965 - val_loss: 0.0115\nEpoch 6/15\n\u001b[1m3447/3447\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 15ms/step - accuracy: 0.9974 - loss: 0.0081 - val_accuracy: 0.9968 - val_loss: 0.0109\nEpoch 7/15\n\u001b[1m3447/3447\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 15ms/step - accuracy: 0.9978 - loss: 0.0068 - val_accuracy: 0.9971 - val_loss: 0.0106\nEpoch 8/15\n\u001b[1m3447/3447\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 15ms/step - accuracy: 0.9980 - loss: 0.0061 - val_accuracy: 0.9971 - val_loss: 0.0102\nEpoch 9/15\n\u001b[1m3447/3447\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 15ms/step - accuracy: 0.9983 - loss: 0.0052 - val_accuracy: 0.9974 - val_loss: 0.0097\nEpoch 10/15\n\u001b[1m3447/3447\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 15ms/step - accuracy: 0.9985 - loss: 0.0045 - val_accuracy: 0.9975 - val_loss: 0.0094\nEpoch 11/15\n\u001b[1m3447/3447\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 15ms/step - accuracy: 0.9986 - loss: 0.0042 - val_accuracy: 0.9976 - val_loss: 0.0091\nEpoch 12/15\n\u001b[1m3447/3447\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 15ms/step - accuracy: 0.9987 - loss: 0.0038 - val_accuracy: 0.9977 - val_loss: 0.0087\nEpoch 13/15\n\u001b[1m3447/3447\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 15ms/step - accuracy: 0.9989 - loss: 0.0035 - val_accuracy: 0.9975 - val_loss: 0.0096\nEpoch 14/15\n\u001b[1m3447/3447\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 15ms/step - accuracy: 0.9989 - loss: 0.0033 - val_accuracy: 0.9977 - val_loss: 0.0090\nEpoch 15/15\n\u001b[1m3447/3447\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 15ms/step - accuracy: 0.9990 - loss: 0.0031 - val_accuracy: 0.9977 - val_loss: 0.0091\n","output_type":"stream"},{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"<keras.src.callbacks.history.History at 0x7fd1942eca10>"},"metadata":{}}],"execution_count":17},{"cell_type":"code","source":"def translate(text):\n    seq = pad_sequences(en_tok.texts_to_sequences([text]), maxlen=en_seq.shape[1], padding='post')\n    out_seq = [fr_tok.word_index['<start>']]\n    for _ in range(fr_seq.shape[1]):\n        dec_seq = pad_sequences([out_seq], maxlen=dec_in.shape[1], padding='post')\n        pred = model.predict([seq, dec_seq], verbose=0)[0, len(out_seq)-1]\n        next_word = np.argmax(pred)\n        if next_word == fr_tok.word_index['<end>']: break\n        out_seq.append(next_word)\n    return ' '.join([fr_tok.index_word[i] for i in out_seq[1:]])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T05:19:21.112256Z","iopub.execute_input":"2025-09-18T05:19:21.113101Z","iopub.status.idle":"2025-09-18T05:19:21.119396Z","shell.execute_reply.started":"2025-09-18T05:19:21.113078Z","shell.execute_reply":"2025-09-18T05:19:21.118747Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"print(translate(\"the weather is cold today\"))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T05:19:23.254569Z","iopub.execute_input":"2025-09-18T05:19:23.255070Z","iopub.status.idle":"2025-09-18T05:19:24.166462Z","shell.execute_reply.started":"2025-09-18T05:19:23.255046Z","shell.execute_reply":"2025-09-18T05:19:24.165762Z"}},"outputs":[{"name":"stdout","text":"le requin est mon animal préféré .\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}